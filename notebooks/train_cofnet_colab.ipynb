{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COFNet Training on SkyWatch Dataset\n",
    "\n",
    "**Continuous-scale Object Field Network** - A novel architecture combining:\n",
    "- Mamba-SSM backbone for efficient sequence modeling\n",
    "- Continuous Scale Field (CSF) for scale-equivariant features\n",
    "- Diffusion-based box refinement\n",
    "- Scale-Diffusion Self-Supervision (SDSS)\n",
    "\n",
    "This notebook trains COFNet on the SkyWatch dataset (planes, wildlife, meteorites in night sky images)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone COFNet repository\n",
    "!git clone https://github.com/Deibler/COFNet.git\n",
    "%cd COFNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install torch torchvision --upgrade\n",
    "!pip install mamba-ssm causal-conv1d\n",
    "!pip install huggingface_hub wandb\n",
    "!pip install pycocotools\n",
    "!pip install einops timm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download SkyWatch Dataset from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download, snapshot_download\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Download the processed dataset\n",
    "print(\"Downloading SkyWatch dataset from HuggingFace...\")\n",
    "\n",
    "# Try to download the full dataset\n",
    "try:\n",
    "    dataset_path = snapshot_download(\n",
    "        repo_id=\"Deibler/skywatch-dataset\",\n",
    "        repo_type=\"dataset\",\n",
    "        local_dir=\"./data\"\n",
    "    )\n",
    "    print(f\"Dataset downloaded to: {dataset_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading: {e}\")\n",
    "    print(\"Trying alternative download...\")\n",
    "    \n",
    "    # Alternative: download zip file\n",
    "    zip_path = hf_hub_download(\n",
    "        repo_id=\"Deibler/skywatch-dataset\",\n",
    "        filename=\"skywatch_processed.zip\",\n",
    "        repo_type=\"dataset\"\n",
    "    )\n",
    "    \n",
    "    # Extract\n",
    "    os.makedirs(\"./data\", exist_ok=True)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        z.extractall(\"./data\")\n",
    "    print(\"Dataset extracted to ./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset structure\n",
    "import os\n",
    "\n",
    "def count_files(path):\n",
    "    if os.path.exists(path):\n",
    "        return len([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))])\n",
    "    return 0\n",
    "\n",
    "# Check for different possible structures\n",
    "possible_paths = [\n",
    "    \"./data/processed\",\n",
    "    \"./data\",\n",
    "    \"./data/skywatch\"\n",
    "]\n",
    "\n",
    "DATA_ROOT = None\n",
    "for path in possible_paths:\n",
    "    train_path = os.path.join(path, \"train\", \"images\")\n",
    "    if os.path.exists(train_path):\n",
    "        DATA_ROOT = path\n",
    "        break\n",
    "\n",
    "if DATA_ROOT:\n",
    "    print(f\"Dataset root: {DATA_ROOT}\")\n",
    "    print(f\"Train images: {count_files(os.path.join(DATA_ROOT, 'train', 'images'))}\")\n",
    "    print(f\"Valid images: {count_files(os.path.join(DATA_ROOT, 'valid', 'images'))}\")\n",
    "    print(f\"Test images: {count_files(os.path.join(DATA_ROOT, 'test', 'images'))}\")\n",
    "else:\n",
    "    print(\"Dataset structure:\")\n",
    "    !find ./data -type f | head -20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import COFNet Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './src')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from models.cofnet import COFNet\n",
    "from data.coco_dataset import COCODataset, collate_fn\n",
    "from training.ssl import ScaleContrastiveLearning, CrossScaleReconstruction\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Configuration\n",
    "CONFIG = {\n",
    "    # Data\n",
    "    'data_root': DATA_ROOT or './data/processed',\n",
    "    'image_size': (512, 512),  # Resize images\n",
    "    'batch_size': 4,  # Adjust based on GPU memory\n",
    "    'num_workers': 2,\n",
    "    \n",
    "    # Model\n",
    "    'num_classes': 3,  # Plane, WildLife, meteorite\n",
    "    'backbone_dims': [64, 128, 256, 512],  # Feature dimensions\n",
    "    'csf_dim': 128,  # CSF output dimension\n",
    "    'num_queries': 100,  # Detection queries\n",
    "    'diffusion_steps_train': 100,\n",
    "    'diffusion_steps_infer': 10,\n",
    "    \n",
    "    # Training\n",
    "    'epochs': 50,\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 0.01,\n",
    "    'use_ssl': True,  # Enable self-supervised learning\n",
    "    'ssl_weight': 0.1,  # Weight for SSL losses\n",
    "    \n",
    "    # Logging\n",
    "    'log_interval': 10,\n",
    "    'save_interval': 5,\n",
    "    'use_wandb': False,  # Set to True to enable W&B logging\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_root = Path(CONFIG['data_root'])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = COCODataset(\n",
    "    img_folder=str(data_root / \"train\" / \"images\"),\n",
    "    ann_file=str(data_root / \"train_coco.json\"),\n",
    "    image_size=CONFIG['image_size'],\n",
    ")\n",
    "\n",
    "val_dataset = COCODataset(\n",
    "    img_folder=str(data_root / \"valid\" / \"images\"),\n",
    "    ann_file=str(data_root / \"valid_coco.json\"),\n",
    "    image_size=CONFIG['image_size'],\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a sample\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "sample = train_dataset[0]\n",
    "img = sample['image'].permute(1, 2, 0).numpy()\n",
    "boxes = sample['boxes']\n",
    "labels = sample['labels']\n",
    "\n",
    "CLASS_NAMES = ['Plane', 'WildLife', 'meteorite']\n",
    "COLORS = ['red', 'green', 'blue']\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "ax.imshow(img)\n",
    "\n",
    "H, W = img.shape[:2]\n",
    "for box, label in zip(boxes, labels):\n",
    "    # Convert from [cx, cy, w, h] normalized to [x, y, w, h] pixels\n",
    "    cx, cy, w, h = box.numpy()\n",
    "    x = (cx - w/2) * W\n",
    "    y = (cy - h/2) * H\n",
    "    w_px = w * W\n",
    "    h_px = h * H\n",
    "    \n",
    "    rect = patches.Rectangle(\n",
    "        (x, y), w_px, h_px,\n",
    "        linewidth=2,\n",
    "        edgecolor=COLORS[label],\n",
    "        facecolor='none'\n",
    "    )\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(x, y-5, CLASS_NAMES[label], color=COLORS[label], fontsize=12)\n",
    "\n",
    "ax.set_title('Sample Training Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create COFNet model\n",
    "model = COFNet(\n",
    "    num_classes=CONFIG['num_classes'],\n",
    "    backbone_dims=CONFIG['backbone_dims'],\n",
    "    csf_dim=CONFIG['csf_dim'],\n",
    "    num_queries=CONFIG['num_queries'],\n",
    "    diffusion_steps_train=CONFIG['diffusion_steps_train'],\n",
    "    diffusion_steps_infer=CONFIG['diffusion_steps_infer'],\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "num_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {num_params:,}\")\n",
    "print(f\"Trainable parameters: {num_trainable:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SSL modules (optional but recommended)\n",
    "ssl_modules = None\n",
    "if CONFIG['use_ssl']:\n",
    "    print(\"Creating SSL modules...\")\n",
    "    scl = ScaleContrastiveLearning(\n",
    "        feature_dim=CONFIG['csf_dim'],\n",
    "        num_scales=8\n",
    "    ).to(device)\n",
    "    \n",
    "    csr = CrossScaleReconstruction(\n",
    "        feature_dim=CONFIG['csf_dim'],\n",
    "        num_scales=8\n",
    "    ).to(device)\n",
    "    \n",
    "    ssl_modules = (scl, csr)\n",
    "    print(\"SSL modules created: ScaleContrastiveLearning, CrossScaleReconstruction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_detection_losses(outputs, targets, device):\n",
    "    \"\"\"Compute detection losses (classification + box regression).\"\"\"\n",
    "    pred_boxes = outputs['pred_boxes']\n",
    "    pred_logits = outputs['pred_logits']\n",
    "    \n",
    "    B = pred_boxes.shape[0]\n",
    "    total_cls_loss = torch.tensor(0.0, device=device)\n",
    "    total_box_loss = torch.tensor(0.0, device=device)\n",
    "    num_targets = 0\n",
    "    \n",
    "    for b in range(B):\n",
    "        gt_boxes = targets[b]['boxes'].to(device)\n",
    "        gt_labels = targets[b]['labels'].to(device)\n",
    "        \n",
    "        if len(gt_boxes) == 0:\n",
    "            continue\n",
    "        \n",
    "        pred_b = pred_boxes[b]  # [num_queries, 4]\n",
    "        logits_b = pred_logits[b]  # [num_queries, num_classes]\n",
    "        \n",
    "        # Simple matching: for each GT, find closest prediction\n",
    "        for gt_box, gt_label in zip(gt_boxes, gt_labels):\n",
    "            # Find closest prediction by L1 distance\n",
    "            dists = (pred_b - gt_box.unsqueeze(0)).abs().sum(dim=-1)\n",
    "            closest_idx = dists.argmin()\n",
    "            \n",
    "            # Box loss (L1 + GIoU)\n",
    "            box_loss = nn.functional.l1_loss(pred_b[closest_idx], gt_box)\n",
    "            total_box_loss = total_box_loss + box_loss\n",
    "            \n",
    "            # Classification loss\n",
    "            cls_loss = nn.functional.cross_entropy(\n",
    "                logits_b[closest_idx].unsqueeze(0),\n",
    "                gt_label.unsqueeze(0)\n",
    "            )\n",
    "            total_cls_loss = total_cls_loss + cls_loss\n",
    "            num_targets += 1\n",
    "    \n",
    "    # Normalize by number of targets\n",
    "    if num_targets > 0:\n",
    "        total_cls_loss = total_cls_loss / num_targets\n",
    "        total_box_loss = total_box_loss / num_targets\n",
    "    \n",
    "    return total_cls_loss, total_box_loss\n",
    "\n",
    "\n",
    "def train_epoch(model, loader, optimizer, ssl_modules, device, epoch, config):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    total_cls_loss = 0.0\n",
    "    total_box_loss = 0.0\n",
    "    total_diff_loss = 0.0\n",
    "    total_ssl_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch_idx, batch in enumerate(loader):\n",
    "        images = batch['images'].to(device)\n",
    "        targets = batch['targets']\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images, targets)\n",
    "        \n",
    "        # Detection losses\n",
    "        diffusion_loss = outputs.get('loss_diffusion', torch.tensor(0.0, device=device))\n",
    "        cls_loss, box_loss = compute_detection_losses(outputs, targets, device)\n",
    "        \n",
    "        # SSL losses (every other batch to save compute)\n",
    "        ssl_loss = torch.tensor(0.0, device=device)\n",
    "        if ssl_modules is not None and batch_idx % 2 == 0:\n",
    "            scl, csr = ssl_modules\n",
    "            scl_loss = scl(model, images)['total']\n",
    "            csr_loss = csr(model, images)['total']\n",
    "            ssl_loss = (scl_loss + csr_loss) * config['ssl_weight']\n",
    "        \n",
    "        # Total loss\n",
    "        loss = diffusion_loss + cls_loss + 5.0 * box_loss + ssl_loss\n",
    "        \n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        # Update\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track losses\n",
    "        total_loss += loss.item()\n",
    "        total_cls_loss += cls_loss.item()\n",
    "        total_box_loss += box_loss.item()\n",
    "        total_diff_loss += diffusion_loss.item()\n",
    "        total_ssl_loss += ssl_loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Log progress\n",
    "        if (batch_idx + 1) % config['log_interval'] == 0:\n",
    "            avg_loss = total_loss / num_batches\n",
    "            print(f\"  [{batch_idx + 1}/{len(loader)}] \"\n",
    "                  f\"loss={avg_loss:.4f} \"\n",
    "                  f\"(cls={cls_loss.item():.3f}, \"\n",
    "                  f\"box={box_loss.item():.3f}, \"\n",
    "                  f\"diff={diffusion_loss.item():.3f})\")\n",
    "    \n",
    "    return {\n",
    "        'loss': total_loss / max(num_batches, 1),\n",
    "        'cls_loss': total_cls_loss / max(num_batches, 1),\n",
    "        'box_loss': total_box_loss / max(num_batches, 1),\n",
    "        'diff_loss': total_diff_loss / max(num_batches, 1),\n",
    "        'ssl_loss': total_ssl_loss / max(num_batches, 1),\n",
    "    }\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader, device):\n",
    "    \"\"\"Validate the model.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    total_box_error = 0.0\n",
    "    total_cls_correct = 0\n",
    "    num_boxes = 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        images = batch['images'].to(device)\n",
    "        targets = batch['targets']\n",
    "        \n",
    "        outputs = model(images)\n",
    "        pred_boxes = outputs['pred_boxes']\n",
    "        pred_logits = outputs['pred_logits']\n",
    "        \n",
    "        for b, target in enumerate(targets):\n",
    "            gt_boxes = target['boxes'].to(device)\n",
    "            gt_labels = target['labels'].to(device)\n",
    "            \n",
    "            if len(gt_boxes) == 0:\n",
    "                continue\n",
    "            \n",
    "            for gt_box, gt_label in zip(gt_boxes, gt_labels):\n",
    "                # Find closest prediction\n",
    "                dists = (pred_boxes[b] - gt_box.unsqueeze(0)).abs().sum(dim=-1)\n",
    "                closest_idx = dists.argmin()\n",
    "                min_dist = dists.min()\n",
    "                \n",
    "                total_box_error += min_dist.item()\n",
    "                \n",
    "                # Check classification\n",
    "                pred_label = pred_logits[b, closest_idx].argmax()\n",
    "                if pred_label == gt_label:\n",
    "                    total_cls_correct += 1\n",
    "                \n",
    "                num_boxes += 1\n",
    "    \n",
    "    return {\n",
    "        'box_error': total_box_error / max(num_boxes, 1),\n",
    "        'cls_accuracy': total_cls_correct / max(num_boxes, 1),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path('./output')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=CONFIG['lr'],\n",
    "    weight_decay=CONFIG['weight_decay']\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=CONFIG['epochs'],\n",
    "    eta_min=1e-6\n",
    ")\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_box_error': [],\n",
    "    'val_cls_accuracy': [],\n",
    "    'lr': [],\n",
    "}\n",
    "\n",
    "best_val_error = float('inf')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Starting COFNet Training\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Epochs: {CONFIG['epochs']}\")\n",
    "print(f\"Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"Learning rate: {CONFIG['lr']}\")\n",
    "print(f\"SSL enabled: {CONFIG['use_ssl']}\")\n",
    "print(\"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop\n",
    "for epoch in range(CONFIG['epochs']):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch + 1}/{CONFIG['epochs']}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Train\n",
    "    train_metrics = train_epoch(\n",
    "        model, train_loader, optimizer, ssl_modules, device, epoch, CONFIG\n",
    "    )\n",
    "    \n",
    "    # Validate\n",
    "    val_metrics = validate(model, val_loader, device)\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    # Log metrics\n",
    "    print(f\"\\n  Train Loss: {train_metrics['loss']:.4f}\")\n",
    "    print(f\"    - Classification: {train_metrics['cls_loss']:.4f}\")\n",
    "    print(f\"    - Box Regression: {train_metrics['box_loss']:.4f}\")\n",
    "    print(f\"    - Diffusion: {train_metrics['diff_loss']:.4f}\")\n",
    "    if CONFIG['use_ssl']:\n",
    "        print(f\"    - SSL: {train_metrics['ssl_loss']:.4f}\")\n",
    "    print(f\"  Val Box Error: {val_metrics['box_error']:.4f}\")\n",
    "    print(f\"  Val Cls Accuracy: {val_metrics['cls_accuracy']:.2%}\")\n",
    "    print(f\"  Learning Rate: {current_lr:.6f}\")\n",
    "    print(f\"  Time: {elapsed:.1f}s\")\n",
    "    \n",
    "    # Track history\n",
    "    history['train_loss'].append(train_metrics['loss'])\n",
    "    history['val_box_error'].append(val_metrics['box_error'])\n",
    "    history['val_cls_accuracy'].append(val_metrics['cls_accuracy'])\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_metrics['box_error'] < best_val_error:\n",
    "        best_val_error = val_metrics['box_error']\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_box_error': best_val_error,\n",
    "            'config': CONFIG,\n",
    "        }, output_dir / 'best_model.pth')\n",
    "        print(f\"  -> Saved best model (box_error: {best_val_error:.4f})\")\n",
    "    \n",
    "    # Periodic checkpoint\n",
    "    if (epoch + 1) % CONFIG['save_interval'] == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'history': history,\n",
    "            'config': CONFIG,\n",
    "        }, output_dir / f'checkpoint_epoch_{epoch + 1}.pth')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Complete!\")\n",
    "print(f\"Best validation box error: {best_val_error:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Training loss\n",
    "axes[0, 0].plot(history['train_loss'])\n",
    "axes[0, 0].set_title('Training Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Validation box error\n",
    "axes[0, 1].plot(history['val_box_error'])\n",
    "axes[0, 1].set_title('Validation Box Error')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Box Error')\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# Classification accuracy\n",
    "axes[1, 0].plot(history['val_cls_accuracy'])\n",
    "axes[1, 0].set_title('Validation Classification Accuracy')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Accuracy')\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# Learning rate\n",
    "axes[1, 1].plot(history['lr'])\n",
    "axes[1, 1].set_title('Learning Rate')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('LR')\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'training_curves.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Inference & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load(output_dir / 'best_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def visualize_predictions(model, dataset, device, num_samples=4, conf_threshold=0.3):\n",
    "    \"\"\"Visualize model predictions on sample images.\"\"\"\n",
    "    CLASS_NAMES = ['Plane', 'WildLife', 'meteorite']\n",
    "    COLORS = ['red', 'green', 'blue']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 16))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    indices = torch.randperm(len(dataset))[:num_samples]\n",
    "    \n",
    "    for ax_idx, sample_idx in enumerate(indices):\n",
    "        sample = dataset[sample_idx.item()]\n",
    "        img = sample['image'].unsqueeze(0).to(device)\n",
    "        \n",
    "        # Get predictions\n",
    "        outputs = model(img)\n",
    "        pred_boxes = outputs['pred_boxes'][0]  # [num_queries, 4]\n",
    "        pred_logits = outputs['pred_logits'][0]  # [num_queries, num_classes]\n",
    "        \n",
    "        # Get confidences\n",
    "        pred_probs = torch.softmax(pred_logits, dim=-1)\n",
    "        pred_scores, pred_labels = pred_probs.max(dim=-1)\n",
    "        \n",
    "        # Filter by confidence\n",
    "        mask = pred_scores > conf_threshold\n",
    "        \n",
    "        # Plot image\n",
    "        img_np = sample['image'].permute(1, 2, 0).numpy()\n",
    "        axes[ax_idx].imshow(img_np)\n",
    "        \n",
    "        H, W = img_np.shape[:2]\n",
    "        \n",
    "        # Plot predictions\n",
    "        for box, label, score in zip(pred_boxes[mask], pred_labels[mask], pred_scores[mask]):\n",
    "            box = box.cpu().numpy()\n",
    "            label = label.cpu().item()\n",
    "            score = score.cpu().item()\n",
    "            \n",
    "            cx, cy, w, h = box\n",
    "            x = (cx - w/2) * W\n",
    "            y = (cy - h/2) * H\n",
    "            w_px = w * W\n",
    "            h_px = h * H\n",
    "            \n",
    "            rect = patches.Rectangle(\n",
    "                (x, y), w_px, h_px,\n",
    "                linewidth=2,\n",
    "                edgecolor=COLORS[label],\n",
    "                facecolor='none'\n",
    "            )\n",
    "            axes[ax_idx].add_patch(rect)\n",
    "            axes[ax_idx].text(\n",
    "                x, y-5,\n",
    "                f\"{CLASS_NAMES[label]}: {score:.2f}\",\n",
    "                color=COLORS[label],\n",
    "                fontsize=10,\n",
    "                fontweight='bold'\n",
    "            )\n",
    "        \n",
    "        # Plot ground truth (dashed)\n",
    "        gt_boxes = sample['boxes']\n",
    "        gt_labels = sample['labels']\n",
    "        for box, label in zip(gt_boxes, gt_labels):\n",
    "            box = box.numpy()\n",
    "            label = label.item()\n",
    "            \n",
    "            cx, cy, w, h = box\n",
    "            x = (cx - w/2) * W\n",
    "            y = (cy - h/2) * H\n",
    "            w_px = w * W\n",
    "            h_px = h * H\n",
    "            \n",
    "            rect = patches.Rectangle(\n",
    "                (x, y), w_px, h_px,\n",
    "                linewidth=2,\n",
    "                edgecolor=COLORS[label],\n",
    "                facecolor='none',\n",
    "                linestyle='--'\n",
    "            )\n",
    "            axes[ax_idx].add_patch(rect)\n",
    "        \n",
    "        axes[ax_idx].set_title(f'Sample {sample_idx.item()}')\n",
    "        axes[ax_idx].axis('off')\n",
    "    \n",
    "    plt.suptitle('Predictions (solid) vs Ground Truth (dashed)', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'predictions.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions(model, val_dataset, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model with all components\n",
    "final_checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'config': CONFIG,\n",
    "    'history': history,\n",
    "    'best_val_error': best_val_error,\n",
    "    'num_epochs': CONFIG['epochs'],\n",
    "}\n",
    "\n",
    "if ssl_modules is not None:\n",
    "    scl, csr = ssl_modules\n",
    "    final_checkpoint['scl_state_dict'] = scl.state_dict()\n",
    "    final_checkpoint['csr_state_dict'] = csr.state_dict()\n",
    "\n",
    "torch.save(final_checkpoint, output_dir / 'cofnet_skywatch_final.pth')\n",
    "print(f\"Final model saved to: {output_dir / 'cofnet_skywatch_final.pth'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the trained model (for Colab)\n",
    "from google.colab import files\n",
    "files.download(str(output_dir / 'cofnet_skywatch_final.pth'))\n",
    "files.download(str(output_dir / 'training_curves.png'))\n",
    "files.download(str(output_dir / 'predictions.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook trained COFNet on the SkyWatch dataset for detecting:\n",
    "- **Planes** - Aircraft in night sky images\n",
    "- **Wildlife** - Birds and other animals\n",
    "- **Meteorites** - Rare meteor streaks\n",
    "\n",
    "### Key Components:\n",
    "1. **Mamba-SSM Backbone** - Efficient state-space modeling for visual features\n",
    "2. **Continuous Scale Field** - Scale-equivariant feature representations\n",
    "3. **Diffusion Box Refiner** - Iterative refinement of bounding boxes\n",
    "4. **SDSS** - Self-supervised learning exploiting the architecture\n",
    "\n",
    "### Next Steps:\n",
    "- Fine-tune hyperparameters (learning rate, batch size, epochs)\n",
    "- Experiment with different backbone sizes\n",
    "- Add data augmentation\n",
    "- Use full SDSS pretraining before supervised training"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
